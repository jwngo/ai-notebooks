{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Found 18480 images belonging to 2 classes.\n{'original': 0, 'upscaled': 1}\nFound 4620 images belonging to 2 classes.\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization, LeakyReLU\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "epochs = 40\n",
    "batch_size = 32\n",
    "\n",
    "image_gen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    validation_split=0.2,\n",
    "                    )\n",
    "train_dir = os.path.join(os.getcwd(), 'train_dataset')\n",
    "\n",
    "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
    "                                                     directory=train_dir,\n",
    "                                                     shuffle= True,\n",
    "                                                     class_mode='sparse',\n",
    "                                                     color_mode='grayscale',\n",
    "                                                     subset='training',\n",
    "                                                     target_size = (64, 64))\n",
    "print(train_data_gen.class_indices)\n",
    "val_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
    "                                                directory = train_dir,\n",
    "                                                shuffle=True,\n",
    "                                                class_mode='sparse',\n",
    "                                                color_mode='grayscale',\n",
    "                                                subset='validation',\n",
    "                                                target_size=(64,64))\n",
    "\n",
    "                                        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "\n",
    "model.add(Conv2D(16, (3,3), input_shape = (64, 64, 1)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(4,4)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "# Compiling the model using some basic parameters\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\"\n",
    "              ,optimizer=\"adam\"\n",
    "              ,metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train for 577 steps, validate for 144 steps\nEpoch 1/40\n576/577 [============================>.] - ETA: 0s - loss: 0.6964 - accuracy: 0.5456\nEpoch 00001: val_loss improved from inf to 0.69946, saving model to /Users/jiawei/CS386/project3/models/new_detect_upscale_model_1.h5\n577/577 [==============================] - 403s 698ms/step - loss: 0.6964 - accuracy: 0.5456 - val_loss: 0.6995 - val_accuracy: 0.5584\nEpoch 2/40\n576/577 [============================>.] - ETA: 0s - loss: 0.6799 - accuracy: 0.5824\nEpoch 00002: val_loss improved from 0.69946 to 0.65965, saving model to /Users/jiawei/CS386/project3/models/new_detect_upscale_model_2.h5\n577/577 [==============================] - 449s 779ms/step - loss: 0.6799 - accuracy: 0.5824 - val_loss: 0.6596 - val_accuracy: 0.5801\nEpoch 3/40\n576/577 [============================>.] - ETA: 0s - loss: 0.3683 - accuracy: 0.8282\nEpoch 00003: val_loss improved from 0.65965 to 0.09785, saving model to /Users/jiawei/CS386/project3/models/new_detect_upscale_model_3.h5\n577/577 [==============================] - 361s 625ms/step - loss: 0.3685 - accuracy: 0.8282 - val_loss: 0.0979 - val_accuracy: 0.9681\nEpoch 4/40\n576/577 [============================>.] - ETA: 0s - loss: 0.1855 - accuracy: 0.9333\nEpoch 00004: val_loss improved from 0.09785 to 0.05540, saving model to /Users/jiawei/CS386/project3/models/new_detect_upscale_model_4.h5\n577/577 [==============================] - 361s 626ms/step - loss: 0.1855 - accuracy: 0.9333 - val_loss: 0.0554 - val_accuracy: 0.9852\nEpoch 5/40\n576/577 [============================>.] - ETA: 0s - loss: 0.1742 - accuracy: 0.9367\nEpoch 00005: val_loss did not improve from 0.05540\n577/577 [==============================] - 428s 741ms/step - loss: 0.1741 - accuracy: 0.9367 - val_loss: 0.1674 - val_accuracy: 0.9297\nEpoch 6/40\n576/577 [============================>.] - ETA: 0s - loss: 0.1678 - accuracy: 0.9380\nEpoch 00006: val_loss improved from 0.05540 to 0.05515, saving model to /Users/jiawei/CS386/project3/models/new_detect_upscale_model_6.h5\n577/577 [==============================] - 434s 752ms/step - loss: 0.1675 - accuracy: 0.9381 - val_loss: 0.0551 - val_accuracy: 0.9820\nEpoch 7/40\n576/577 [============================>.] - ETA: 0s - loss: 0.1589 - accuracy: 0.9401\nEpoch 00007: val_loss improved from 0.05515 to 0.03445, saving model to /Users/jiawei/CS386/project3/models/new_detect_upscale_model_7.h5\n577/577 [==============================] - 426s 739ms/step - loss: 0.1588 - accuracy: 0.9401 - val_loss: 0.0345 - val_accuracy: 0.9924\nEpoch 8/40\n576/577 [============================>.] - ETA: 0s - loss: 0.1563 - accuracy: 0.9421\nEpoch 00008: val_loss did not improve from 0.03445\n577/577 [==============================] - 419s 727ms/step - loss: 0.1561 - accuracy: 0.9422 - val_loss: 0.0357 - val_accuracy: 0.9915\nEpoch 9/40\n576/577 [============================>.] - ETA: 0s - loss: 0.1534 - accuracy: 0.9441\nEpoch 00009: val_loss did not improve from 0.03445\n577/577 [==============================] - 412s 715ms/step - loss: 0.1534 - accuracy: 0.9441 - val_loss: 0.9514 - val_accuracy: 0.6847\nEpoch 10/40\n576/577 [============================>.] - ETA: 0s - loss: 0.1508 - accuracy: 0.9462\nEpoch 00010: val_loss did not improve from 0.03445\n577/577 [==============================] - 427s 740ms/step - loss: 0.1508 - accuracy: 0.9462 - val_loss: 0.1618 - val_accuracy: 0.9382\nEpoch 11/40\n576/577 [============================>.] - ETA: 0s - loss: 0.1501 - accuracy: 0.9462\nEpoch 00011: val_loss did not improve from 0.03445\n577/577 [==============================] - 435s 755ms/step - loss: 0.1500 - accuracy: 0.9463 - val_loss: 0.0418 - val_accuracy: 0.9859\nEpoch 00011: early stopping\n"
    }
   ],
   "source": [
    "import keras\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(os.getcwd(), 'models/new_detect_upscale_model_{epoch}.h5'),\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        # Stop training when `val_loss` is no longer improving\n",
    "        monitor='val_loss',\n",
    "        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "        min_delta=1e-2,\n",
    "        # \"no longer improving\" being further defined as \"for at least 3 epochs\"\n",
    "        patience=4,\n",
    "        verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(train_data_gen, validation_data=val_data_gen, epochs=epochs,\n",
    "                    steps_per_epoch = train_data_gen.samples // batch_size,\n",
    "                    validation_steps = val_data_gen.samples // batch_size,\n",
    "                    callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Found 600 images belonging to 2 classes.\n{'original': 0, 'upscaled': 1}\n"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model( os.getcwd() + '/models/new_detect_upscale_model_7.h5')\n",
    "''' 64x64 patch taken from the centre of all 200 4K images; \n",
    "    200 64x64 patch of Bicubic upscaled from 1080p\n",
    "    and 200 64x64 patch of Lanczos upscaled from 1080p '''\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_dir = os.path.join(os.getcwd(), 'test_dataset')\n",
    "test_data_gen = test_gen.flow_from_directory(batch_size=batch_size,\n",
    "                                                     directory=test_dir,\n",
    "                                                     shuffle= True,\n",
    "                                                     class_mode='sparse',\n",
    "                                                     color_mode='grayscale',\n",
    "                                                     target_size = (64, 64))\n",
    "print(test_data_gen.class_indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "=============== Train dataset metrics ===============\n578/578 [==============================] - 69s 120ms/step - loss: 0.1107 - accuracy: 0.9601\n[0.11066196460895575, 0.96006495]\n=============== Validation dataset metrics ===============\n145/145 [==============================] - 16s 109ms/step - loss: 0.0343 - accuracy: 0.9924\n[0.03434816428684983, 0.99242425]\n=============== Test dataset metrics ===============\n19/19 [==============================] - 2s 118ms/step - loss: 0.1039 - accuracy: 0.9633\n[0.1039439278997873, 0.9633333]\n"
    }
   ],
   "source": [
    "print(\"=============== Train dataset metrics ===============\")\n",
    "print(model.evaluate(train_data_gen))\n",
    "print(\"=============== Validation dataset metrics ===============\")\n",
    "print(model.evaluate(val_data_gen))\n",
    "print(\"=============== Test dataset metrics ===============\")\n",
    "print(model.evaluate(test_data_gen))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.04575605, 0.95424396],\n       [0.07001948, 0.92998046],\n       [0.94701076, 0.05298924],\n       ...,\n       [0.99824214, 0.00175788],\n       [0.0092172 , 0.9907828 ],\n       [0.03011798, 0.9698821 ]], dtype=float32)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_data_gen)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "865d8a64-89a6-4b6c-bfd9-005917b2484d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}